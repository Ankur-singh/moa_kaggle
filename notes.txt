## Public -> CV
---------------
- 0.01925 -> 0.016583 (07 models) (2048, 2048)
- 0.01902 -> 0.016455 (07 models) (2048, 1024)
- 0.01900 -> 0.016268 (49 models) (2048, 1024)
- 0.01867 -> 0.015944 (7+7 models) (2048, 1024)

- xxxxxxx -> 0.017485 (07 models) (tabnet)

- Driving License
- Laptop battery

https://www.kaggle.com/cdeotte/rapids-genetic-algorithm-knn-cv-0-01840

## Ideas ##
-----------
- Feature Engineering (worked) and Loss smoothing (didn't work) for training. Refer: https://www.kaggle.com/kushal1506/moa-pytorch-feature-engineering-0-01846
- better values for PCA (genes and cells components) and variance threshold. Refer: https://www.kaggle.com/vbmokin/moa-pytorch-rankgauss-pca-nn-upgrade-3d-visual
- seed (train more than 7 models) can reduce the score to 0.01859 points

Use non-Scored training set
---------------------------
- transfer learning. Take a high preforming model, make predictions and then train the model on the complete dataset again. Just like pseudo labeling. Refer https://www.kaggle.com/kailex/moa-transfer-recipe-with-smoothing
- https://www.kaggle.com/kushal1506/moa-pretrained-non-scored-targets-as-meta-features


Use train_drugs.csv - Done
--------------------------
- Make a local CV 
- create better cross-validation distribution. 

Models - Done
-------------
- use deeper model
- use Fastai model
- see what other people have used

Scheduler - Done
----------------
- ReduceonPlatue
- OneCycleLR
- see what other people have used 

Others - Done
-------------
- Weight decay